{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "from model.edsr import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "         \"n_threads\": 8,\n",
    " \n",
    "        \"n_GPUs\": 1,\n",
    " \n",
    "        \"seed\": 1,\n",
    " \n",
    "        \"scale\": (2,),\n",
    "    \"n_colors\": 3,\n",
    "    \"act\": \"Relu\",\n",
    "    \n",
    "    \"n_resblocks\": 32,\n",
    "    \"n_feats\": 256,\n",
    "    \"shift_mean\": True,\n",
    "    'res_scale':0.1,\n",
    "    \n",
    "        \"rgb_range\": 255\n",
    " })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=EDSR(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=model.head[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.conv.Conv2d"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model.head[0].weight.data\n",
      " tensor([[[[-0.0797,  0.1522,  0.0095],\n",
      "          [-0.1535, -0.0549,  0.0466],\n",
      "          [ 0.0059,  0.0502,  0.0878]],\n",
      "\n",
      "         [[-0.1682,  0.0583, -0.1736],\n",
      "          [-0.0798, -0.1066, -0.0185],\n",
      "          [ 0.1219, -0.0951, -0.0548]],\n",
      "\n",
      "         [[-0.0825,  0.1706,  0.0973],\n",
      "          [-0.1521, -0.0544, -0.0818],\n",
      "          [ 0.0547,  0.1574, -0.1634]]],\n",
      "\n",
      "\n",
      "        [[[-0.1446,  0.1351,  0.0315],\n",
      "          [-0.1477,  0.0923, -0.1474],\n",
      "          [ 0.0526, -0.0746,  0.0264]],\n",
      "\n",
      "         [[ 0.0806,  0.0047,  0.0012],\n",
      "          [ 0.1177,  0.0417,  0.1169],\n",
      "          [ 0.0495,  0.0475,  0.0386]],\n",
      "\n",
      "         [[-0.0075,  0.0476,  0.0706],\n",
      "          [ 0.0819, -0.0520,  0.0678],\n",
      "          [-0.0820,  0.0968, -0.1467]]],\n",
      "\n",
      "\n",
      "        [[[-0.0119, -0.1075,  0.1160],\n",
      "          [-0.0797,  0.0329, -0.0748],\n",
      "          [ 0.1316,  0.1293,  0.0063]],\n",
      "\n",
      "         [[-0.0815, -0.0003,  0.1885],\n",
      "          [-0.1303, -0.1110,  0.0303],\n",
      "          [-0.0145,  0.1523, -0.1371]],\n",
      "\n",
      "         [[ 0.0507, -0.1047, -0.1690],\n",
      "          [ 0.1577, -0.1479, -0.1062],\n",
      "          [-0.0277, -0.1812, -0.1657]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1372, -0.0489,  0.1652],\n",
      "          [-0.1811,  0.1718, -0.1597],\n",
      "          [ 0.0212,  0.1920, -0.1707]],\n",
      "\n",
      "         [[ 0.0438, -0.0006, -0.0684],\n",
      "          [ 0.0151, -0.0020,  0.1044],\n",
      "          [ 0.1499, -0.1729, -0.0021]],\n",
      "\n",
      "         [[ 0.1814, -0.0172,  0.0364],\n",
      "          [ 0.0203,  0.1642,  0.0522],\n",
      "          [-0.0488, -0.0777,  0.0242]]],\n",
      "\n",
      "\n",
      "        [[[-0.0342, -0.0584, -0.1599],\n",
      "          [ 0.0843,  0.0194,  0.0927],\n",
      "          [-0.1748,  0.1534,  0.1280]],\n",
      "\n",
      "         [[ 0.0062, -0.0257, -0.1802],\n",
      "          [-0.0630,  0.1354,  0.0706],\n",
      "          [-0.1912, -0.1374, -0.0567]],\n",
      "\n",
      "         [[-0.1237, -0.1108,  0.1186],\n",
      "          [ 0.1293,  0.1303,  0.1324],\n",
      "          [ 0.0623,  0.1525, -0.1392]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1109, -0.1885,  0.0157],\n",
      "          [ 0.0745, -0.0104, -0.1383],\n",
      "          [-0.1003,  0.1844,  0.1867]],\n",
      "\n",
      "         [[-0.1506,  0.0264, -0.1505],\n",
      "          [ 0.0708,  0.0133,  0.1737],\n",
      "          [-0.1281, -0.0046,  0.1040]],\n",
      "\n",
      "         [[ 0.0285, -0.1013, -0.1751],\n",
      "          [ 0.1388, -0.0255,  0.0725],\n",
      "          [-0.0704,  0.0192,  0.1213]]]])\n",
      "\n",
      "model.head[0].__class__\n",
      " <class 'torch.nn.modules.conv.Conv2d'>\n",
      "\n",
      "model.head[0].kernel_size\n",
      " (3, 3)\n",
      "\n",
      "input.size()\n",
      " torch.Size([32, 3, 224, 224])\n",
      "\n",
      "np.prod(input.size()):  4816896\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    model = EDSR(args)\n",
    "    print(\"\\nmodel.head[0].weight.data\\n\",model.head[0].weight.data)\n",
    "    print('\\nmodel.head[0].__class__\\n',model.head[0].__class__)\n",
    "    print('\\nmodel.head[0].kernel_size\\n',model.head[0].kernel_size)\n",
    "    input = torch.autograd.Variable(torch.randn(32, 3, 224, 224))\n",
    "    print('\\ninput.size()\\n',input.size())\n",
    "    print('\\nnp.prod(input.size()): ',np.prod(input.size()))\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of parameters: 25.56M \n",
      "\n",
      "estimated of size 102.23M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_model_parm_nums(my_models=models.resnet50()):\n",
    "    model = my_models#EDSR(args)\n",
    "    trainable = filter(lambda x: x.requires_grad, model.parameters())\n",
    "    num_params = sum([np.prod(p.size()) for p in filter(lambda x: x.requires_grad, model.parameters())])\n",
    "    print('num of parameters: %.2fM ' % (int(num_params) / 1e6) +'\\n')\n",
    "    print('estimated of size %.2fM ' % (int(num_params) / 1e6*4) +'\\n')\n",
    "print_model_parm_nums()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FLOPs: 356.00G\n",
      "\n",
      "num of parameters: 6.82M \n",
      "\n",
      "estimated of size 27.27M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from model.edsr import *\n",
    "from model.edsr_mobile import *\n",
    "def print_model_parm_flops(my_models=models.resnet50()):\n",
    "    multiply_adds = False\n",
    "    list_conv=[]\n",
    "    def conv_hook(self, input, output):\n",
    "        Tt=lambda x:torch.tensor(x)\n",
    "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
    "        output_channels, output_height, output_width = output[0].size()\n",
    "        kernel_ops = Tt(self.kernel_size[0]) * Tt(self.kernel_size[1]) * Tt(int(self.in_channels / self.groups))* Tt(2 if multiply_adds else 1)\n",
    "        bias_ops = Tt(1 if self.bias is not None else 0)\n",
    "        params = Tt(output_channels) * Tt(kernel_ops + bias_ops)\n",
    "        flops = Tt(batch_size) * Tt(params) * Tt(output_height) * Tt(output_width)\n",
    "        list_conv.append(flops)\n",
    "    list_linear=[]\n",
    "    def linear_hook(self, input, output):\n",
    "        \n",
    "        Tt=lambda x:torch.tensor(x)\n",
    "        batch_size = Tt(input[0].size(0) if input[0].dim() == 2 else 1)\n",
    "\n",
    "        weight_ops = Tt(self.weight.nelement()) * Tt(2 if multiply_adds else 1)\n",
    "        bias_ops = Tt(self.bias.nelement())\n",
    "        flops = Tt(batch_size) * Tt(weight_ops + bias_ops)\n",
    "        list_linear.append(flops)\n",
    "    list_bn=[]\n",
    "    def bn_hook(self, input, output):\n",
    "        list_bn.append(input[0].nelement())\n",
    "        \n",
    "\n",
    "    list_relu=[]\n",
    "    def relu_hook(self, input, output):\n",
    "        list_relu.append(input[0].nelement())\n",
    "\n",
    "    list_pooling=[]\n",
    "    def pooling_hook(self, input, output):\n",
    "        Tt=lambda x:torch.tensor(x)\n",
    "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
    "        output_channels, output_height, output_width = output[0].size()\n",
    "        kernel_ops =Tt(self.kernel_size) * Tt(self.kernel_size)\n",
    "        bias_ops = 0\n",
    "        params = Tt(output_channels) * Tt(kernel_ops + bias_ops)\n",
    "        flops = Tt(batch_size) * Tt(params) * Tt(output_height) * Tt(output_width)\n",
    "        list_pooling.append(flops)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    def register_hook(net):\n",
    "        childrens = list(net.children())\n",
    "        if not childrens:\n",
    "            if isinstance(net, torch.nn.Conv2d):\n",
    "                net.register_forward_hook(conv_hook)\n",
    "            if isinstance(net, torch.nn.Linear):\n",
    "                net.register_forward_hook(linear_hook)\n",
    "            if isinstance(net, torch.nn.BatchNorm2d):\n",
    "                net.register_forward_hook(bn_hook)\n",
    "            if isinstance(net, torch.nn.ReLU):\n",
    "                net.register_forward_hook(relu_hook)\n",
    "            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n",
    "                net.register_forward_hook(pooling_hook)\n",
    "            return\n",
    "        for c in childrens:\n",
    "                register_hook(c)\n",
    "\n",
    "    resnet =my_models\n",
    "     #EDSR(args)\n",
    "    register_hook(resnet)\n",
    "    with torch.no_grad():\n",
    "        input = torch.rand(1,3,224,224)\n",
    "        out = resnet(input)\n",
    "\n",
    "\n",
    "\n",
    "    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling))\n",
    "    \n",
    "    print('Number of FLOPs: %.2fG' % (total_flops / 1e9)+'\\n')\n",
    "mo=EDSR(args)\n",
    "print_model_parm_flops(mo)\n",
    "print_model_parm_nums(mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

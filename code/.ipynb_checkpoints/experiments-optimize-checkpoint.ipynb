{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "from model.edsr import *\n",
    "from model.vdsr import *\n",
    "from model.srcnn import *\n",
    "from model.espcn import *\n",
    "from model.edsr_mobile import *\n",
    "import numpy as np\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "         \"n_GPUs\": 1,\n",
    "        \"scale\": (2,),\n",
    "    \"n_colors\": 3,\n",
    "    \"act\": \"Relu\",\n",
    "    \"n_resblocks\": 32,\n",
    "    \"n_feats\": 256,\n",
    "    \"shift_mean\": True,\n",
    "    'res_scale':0.1,\n",
    "        \"rgb_range\": 255,\n",
    "    'model':'VDSR'\n",
    " })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of parameters: 0.66M \n",
      "\n",
      "estimated of size 2.66M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_model_parm_nums(my_models=VDSR()):\n",
    "    model = my_models#EDSR(args)\n",
    "    trainable = filter(lambda x: x.requires_grad, model.parameters())\n",
    "    num_params = sum([np.prod(p.size()) for p in filter(lambda x: x.requires_grad, model.parameters())])\n",
    "    print('num of parameters: %.2fM ' % (int(num_params) / 1e6) +'\\n')\n",
    "    print('estimated of size %.2fM ' % (int(num_params) / 1e6*4) +'\\n')\n",
    "print_model_parm_nums()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual(_model=models.AlexNet(),_input=torch.randn(1, 3, 224, 224).requires_grad_(True),filename=args.model):\n",
    "    model =_model#VDSR() \n",
    "    \n",
    "    x = _input\n",
    "    y = model(x)\n",
    "    make_dot(y, params=dict(list(model.named_parameters()) + [('x', x)])).render(filename=filename)\n",
    "visual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of FLOPs: 15.503G\n",
      "\n",
      " Conv  layer `s 1f FLOPs: 0.090G\n",
      "\n",
      " Conv  layer `s 2f FLOPs: 1.853G\n",
      "\n",
      " Conv  layer `s 3f FLOPs: 0.926G\n",
      "\n",
      " Conv  layer `s 4f FLOPs: 1.851G\n",
      "\n",
      " Conv  layer `s 5f FLOPs: 0.926G\n",
      "\n",
      " Conv  layer `s 6f FLOPs: 1.850G\n",
      "\n",
      " Conv  layer `s 7f FLOPs: 1.850G\n",
      "\n",
      " Conv  layer `s 8f FLOPs: 0.925G\n",
      "\n",
      " Conv  layer `s 9f FLOPs: 1.850G\n",
      "\n",
      " Conv  layer `s 10f FLOPs: 1.850G\n",
      "\n",
      " Conv  layer `s 11f FLOPs: 0.463G\n",
      "\n",
      " Conv  layer `s 12f FLOPs: 0.463G\n",
      "\n",
      " Conv  layer `s 13f FLOPs: 0.463G\n",
      "\n",
      " linear layer `s 1 of FLOPs: 0.103G\n",
      "\n",
      " linear layer `s 2 of FLOPs: 0.017G\n",
      "\n",
      " linear layer `s 3 of FLOPs: 0.004G\n",
      "\n",
      " activation layer `s 1 of FLOPs: 0.0032G\n",
      "\n",
      " activation layer `s 2 of FLOPs: 0.0032G\n",
      "\n",
      " activation layer `s 3 of FLOPs: 0.0016G\n",
      "\n",
      " activation layer `s 4 of FLOPs: 0.0016G\n",
      "\n",
      " activation layer `s 5 of FLOPs: 0.0008G\n",
      "\n",
      " activation layer `s 6 of FLOPs: 0.0008G\n",
      "\n",
      " activation layer `s 7 of FLOPs: 0.0008G\n",
      "\n",
      " activation layer `s 8 of FLOPs: 0.0004G\n",
      "\n",
      " activation layer `s 9 of FLOPs: 0.0004G\n",
      "\n",
      " activation layer `s 10 of FLOPs: 0.0004G\n",
      "\n",
      " activation layer `s 11 of FLOPs: 0.0001G\n",
      "\n",
      " activation layer `s 12 of FLOPs: 0.0001G\n",
      "\n",
      " activation layer `s 13 of FLOPs: 0.0001G\n",
      "\n",
      " activation layer `s 14 of FLOPs: 0.0000G\n",
      "\n",
      " activation layer `s 15 of FLOPs: 0.0000G\n",
      "\n",
      " pooling layer `s 1 of FLOPs: 0.003G\n",
      "\n",
      " pooling layer `s 2 of FLOPs: 0.002G\n",
      "\n",
      " pooling layer `s 3 of FLOPs: 0.001G\n",
      "\n",
      " pooling layer `s 4 of FLOPs: 0.000G\n",
      "\n",
      " pooling layer `s 5 of FLOPs: 0.000G\n",
      "\n",
      "num of parameters: 138.36M \n",
      "\n",
      "estimated of size 553.43M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_model_parm_flops(my_models=models.resnet50(),_input=torch.rand(1,3,224,224)):\n",
    "    multiply_adds = False\n",
    "    list_conv=[]\n",
    "    def conv_hook(self, input, output):\n",
    "        Tt=lambda x:torch.tensor(x)\n",
    "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
    "        output_channels, output_height, output_width = output[0].size()\n",
    "        kernel_ops = Tt(self.kernel_size[0]) * Tt(self.kernel_size[1]) * Tt(int(self.in_channels / self.groups))* Tt(2 if multiply_adds else 1)\n",
    "        bias_ops = Tt(1 if self.bias is not None else 0)\n",
    "        params = Tt(output_channels) * Tt(kernel_ops + bias_ops)\n",
    "        flops = Tt(batch_size) * Tt(params) * Tt(output_height) * Tt(output_width)\n",
    "        list_conv.append(flops)\n",
    "    list_linear=[]\n",
    "    def linear_hook(self, input, output):\n",
    "        \n",
    "        Tt=lambda x:torch.tensor(x)\n",
    "        batch_size = Tt(input[0].size(0) if input[0].dim() == 2 else 1)\n",
    "\n",
    "        weight_ops = Tt(self.weight.nelement()) * Tt(2 if multiply_adds else 1)\n",
    "        bias_ops = Tt(self.bias.nelement())\n",
    "        flops = Tt(batch_size) * Tt(weight_ops + bias_ops)\n",
    "        list_linear.append(flops)\n",
    "    list_bn=[]\n",
    "    def bn_hook(self, input, output):\n",
    "        list_bn.append(input[0].nelement())\n",
    "        \n",
    "\n",
    "    list_relu=[]\n",
    "    def relu_hook(self, input, output):\n",
    "        list_relu.append(input[0].nelement())\n",
    "\n",
    "    list_pooling=[]\n",
    "    def pooling_hook(self, input, output):\n",
    "        Tt=lambda x:torch.tensor(x)\n",
    "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
    "        output_channels, output_height, output_width = output[0].size()\n",
    "        kernel_ops =Tt(self.kernel_size) * Tt(self.kernel_size)\n",
    "        bias_ops = 0\n",
    "        params = Tt(output_channels) * Tt(kernel_ops + bias_ops)\n",
    "        flops = Tt(batch_size) * Tt(params) * Tt(output_height) * Tt(output_width)\n",
    "        list_pooling.append(flops)\n",
    "           \n",
    "    def register_hook(net):\n",
    "        childrens = list(net.children())\n",
    "        if not childrens:\n",
    "            if isinstance(net, torch.nn.Conv2d):\n",
    "                net.register_forward_hook(conv_hook)\n",
    "            if isinstance(net, torch.nn.Linear):\n",
    "                net.register_forward_hook(linear_hook)\n",
    "            if isinstance(net, torch.nn.BatchNorm2d):\n",
    "                net.register_forward_hook(bn_hook)\n",
    "            if isinstance(net, torch.nn.ReLU):\n",
    "                net.register_forward_hook(relu_hook)\n",
    "            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n",
    "                net.register_forward_hook(pooling_hook)\n",
    "            return\n",
    "        for c in childrens:\n",
    "                register_hook(c)\n",
    "\n",
    "    model =my_models\n",
    "     #EDSR(args)\n",
    "    register_hook(model)\n",
    "    with torch.no_grad():\n",
    "        input = _input\n",
    "        out = model(input)\n",
    "\n",
    "    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling))\n",
    "    print('Total Number of FLOPs: %.3fG' % (total_flops.item() / 1e9)+'\\n')\n",
    "    for i in range(len(list_conv)):\n",
    "        print(' Conv  layer `s '+str(i+1) + 'f FLOPs: %.3fG' % (list_conv[i].item() / 1e9)+'\\n')\n",
    "    for i in range(len(list_linear)):\n",
    "        print(' linear layer `s '+str(i+1) +' of FLOPs: %.3fG' % (list_linear[i].item() / 1e9)+'\\n')\n",
    "    for i in range(len(list_bn)):\n",
    "        print(' bn layer `s '+str(i+1) +' of FLOPs: %.3fG' % (list_bn[i].item() / 1e9)+'\\n')\n",
    "    for i in range(len(list_relu)):\n",
    "        print(' activation layer `s '+str(i+1) +' of FLOPs: %.4fG' % (list_relu[i] / 1e9)+'\\n')\n",
    "    for i in range(len(list_pooling)):\n",
    "        print(' pooling layer `s '+str(i+1) +' of FLOPs: %.3fG' % (list_pooling[i].item() / 1e9)+'\\n')\n",
    "\n",
    "mo=models.vgg16()\n",
    "print_model_parm_flops(mo)\n",
    "print_model_parm_nums(mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

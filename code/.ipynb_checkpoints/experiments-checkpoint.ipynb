{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "from model.edsr import *\n",
    "from model.vdsr import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "         \"n_threads\": 8,\n",
    " \n",
    "        \"n_GPUs\": 1,\n",
    " \n",
    "\n",
    "        \"seed\": 1,\n",
    " \n",
    "        \"scale\": (2,),\n",
    "    \"n_colors\": 3,\n",
    "    \"act\": \"Relu\",\n",
    "    \n",
    "    \"n_resblocks\": 32,\n",
    "    \"n_feats\": 256,\n",
    "    \"shift_mean\": True,\n",
    "    'res_scale':0.1,\n",
    "    \n",
    "        \"rgb_range\": 255\n",
    " })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VDSR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model.head[0].weight.data\n",
      " tensor([[[[ 0.0318, -0.1106,  0.1914],\n",
      "          [-0.0636, -0.1828, -0.1599],\n",
      "          [-0.0373, -0.0097, -0.0080]],\n",
      "\n",
      "         [[ 0.1088,  0.0551, -0.1558],\n",
      "          [ 0.0453, -0.0801, -0.1581],\n",
      "          [-0.0124,  0.1518,  0.0053]],\n",
      "\n",
      "         [[ 0.0277, -0.0464, -0.0654],\n",
      "          [-0.0764, -0.1893, -0.0944],\n",
      "          [ 0.0394, -0.1519,  0.1823]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0580, -0.0132,  0.0599],\n",
      "          [-0.1195,  0.0946,  0.1170],\n",
      "          [-0.0987, -0.0500,  0.0701]],\n",
      "\n",
      "         [[-0.0078, -0.0991, -0.1271],\n",
      "          [-0.1648, -0.0592,  0.0261],\n",
      "          [-0.0153,  0.0807, -0.1918]],\n",
      "\n",
      "         [[-0.0067, -0.0908,  0.0882],\n",
      "          [-0.1331,  0.0291, -0.0525],\n",
      "          [-0.0527,  0.1638,  0.1906]]],\n",
      "\n",
      "\n",
      "        [[[-0.1806, -0.1228, -0.1420],\n",
      "          [ 0.1747, -0.1397,  0.0155],\n",
      "          [ 0.1910, -0.0299, -0.0157]],\n",
      "\n",
      "         [[ 0.1827, -0.0875,  0.1350],\n",
      "          [-0.1424, -0.1198, -0.1252],\n",
      "          [-0.0821, -0.0676,  0.0367]],\n",
      "\n",
      "         [[-0.0952,  0.1648,  0.0032],\n",
      "          [ 0.1521,  0.1886, -0.1131],\n",
      "          [-0.1577, -0.0789,  0.0695]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0272,  0.1509, -0.1869],\n",
      "          [-0.1301, -0.0745, -0.0994],\n",
      "          [ 0.1891,  0.0976,  0.0559]],\n",
      "\n",
      "         [[-0.0676, -0.0672,  0.1551],\n",
      "          [-0.1169,  0.0789,  0.1398],\n",
      "          [ 0.0988, -0.1550, -0.0775]],\n",
      "\n",
      "         [[ 0.1329,  0.0997, -0.0173],\n",
      "          [ 0.0951,  0.1169, -0.1752],\n",
      "          [-0.1166, -0.0247,  0.0946]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0313,  0.0683, -0.1095],\n",
      "          [-0.1518,  0.1573,  0.1090],\n",
      "          [-0.0341, -0.0057,  0.1372]],\n",
      "\n",
      "         [[-0.1110,  0.1830, -0.1342],\n",
      "          [-0.1279, -0.1802,  0.0507],\n",
      "          [ 0.0693, -0.0925, -0.1855]],\n",
      "\n",
      "         [[-0.1049, -0.1772,  0.1468],\n",
      "          [-0.0406, -0.0498,  0.1208],\n",
      "          [ 0.1460, -0.1565,  0.0103]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1413, -0.1114, -0.1600],\n",
      "          [ 0.1167, -0.1340, -0.1074],\n",
      "          [ 0.0468,  0.1650, -0.1837]],\n",
      "\n",
      "         [[-0.1843, -0.0088, -0.1599],\n",
      "          [ 0.1608, -0.0263, -0.1334],\n",
      "          [-0.0926, -0.0602, -0.1740]],\n",
      "\n",
      "         [[-0.0681, -0.0633,  0.0647],\n",
      "          [-0.1156, -0.1532,  0.1069],\n",
      "          [ 0.0354, -0.1737, -0.1544]]]])\n",
      "\n",
      "model.head[0].__class__\n",
      " <class 'torch.nn.modules.conv.Conv2d'>\n",
      "\n",
      "model.head[0].kernel_size\n",
      " (3, 3)\n",
      "\n",
      "input.size()\n",
      " torch.Size([32, 3, 224, 224])\n",
      "\n",
      "np.prod(input.size()):  4816896\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    model = EDSR(args)\n",
    "    print(\"\\nmodel.head[0].weight.data\\n\",model.head[0].weight.data)\n",
    "    print('\\nmodel.head[0].__class__\\n',model.head[0].__class__)\n",
    "    print('\\nmodel.head[0].kernel_size\\n',model.head[0].kernel_size)\n",
    "    input = torch.autograd.Variable(torch.randn(32, 3, 224, 224))\n",
    "    print('\\ninput.size()\\n',input.size())\n",
    "    print('\\nnp.prod(input.size()): ',np.prod(input.size()))\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def VDSR_test():\n",
    "    model = VDSR()\n",
    "    print(\"\\nmodel.head[0].weight.data\\n\",model.head[0].weight.data)\n",
    "    print('\\nmodel.head[0].__class__\\n',model.head[0].__class__)\n",
    "    print('\\nmodel.head[0].kernel_size\\n',model.head[0].kernel_size)\n",
    "    input = torch.autograd.Variable(torch.randn(32, 3, 224, 224))\n",
    "    print('\\ninput.size()\\n',input.size())\n",
    "    print('\\nnp.prod(input.size()): ',np.prod(input.size()))\n",
    "VDSR_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of parameters: 0.66M \n",
      "\n",
      "estimated of size 2.66M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_model_parm_nums(my_models=VDSR()):\n",
    "    model = my_models#EDSR(args)\n",
    "    trainable = filter(lambda x: x.requires_grad, model.parameters())\n",
    "    num_params = sum([np.prod(p.size()) for p in filter(lambda x: x.requires_grad, model.parameters())])\n",
    "    print('num of parameters: %.2fM ' % (int(num_params) / 1e6) +'\\n')\n",
    "    print('estimated of size %.2fM ' % (int(num_params) / 1e6*4) +'\\n')\n",
    "print_model_parm_nums()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FLOPs: 1.00G\n",
      "\n",
      "num of parameters: 0.02M \n",
      "\n",
      "estimated of size 0.09M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from model.edsr import *\n",
    "from model.srcnn import *\n",
    "from model.espcn import *\n",
    "from model.edsr_mobile import *\n",
    "def print_model_parm_flops(my_models=models.resnet50()):\n",
    "    multiply_adds = False\n",
    "    list_conv=[]\n",
    "    def conv_hook(self, input, output):\n",
    "        Tt=lambda x:torch.tensor(x)\n",
    "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
    "        output_channels, output_height, output_width = output[0].size()\n",
    "        kernel_ops = Tt(self.kernel_size[0]) * Tt(self.kernel_size[1]) * Tt(int(self.in_channels / self.groups))* Tt(2 if multiply_adds else 1)\n",
    "        bias_ops = Tt(1 if self.bias is not None else 0)\n",
    "        params = Tt(output_channels) * Tt(kernel_ops + bias_ops)\n",
    "        flops = Tt(batch_size) * Tt(params) * Tt(output_height) * Tt(output_width)\n",
    "        list_conv.append(flops)\n",
    "    list_linear=[]\n",
    "    def linear_hook(self, input, output):\n",
    "        \n",
    "        Tt=lambda x:torch.tensor(x)\n",
    "        batch_size = Tt(input[0].size(0) if input[0].dim() == 2 else 1)\n",
    "\n",
    "        weight_ops = Tt(self.weight.nelement()) * Tt(2 if multiply_adds else 1)\n",
    "        bias_ops = Tt(self.bias.nelement())\n",
    "        flops = Tt(batch_size) * Tt(weight_ops + bias_ops)\n",
    "        list_linear.append(flops)\n",
    "    list_bn=[]\n",
    "    def bn_hook(self, input, output):\n",
    "        list_bn.append(input[0].nelement())\n",
    "        \n",
    "\n",
    "    list_relu=[]\n",
    "    def relu_hook(self, input, output):\n",
    "        list_relu.append(input[0].nelement())\n",
    "\n",
    "    list_pooling=[]\n",
    "    def pooling_hook(self, input, output):\n",
    "        Tt=lambda x:torch.tensor(x)\n",
    "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
    "        output_channels, output_height, output_width = output[0].size()\n",
    "        kernel_ops =Tt(self.kernel_size) * Tt(self.kernel_size)\n",
    "        bias_ops = 0\n",
    "        params = Tt(output_channels) * Tt(kernel_ops + bias_ops)\n",
    "        flops = Tt(batch_size) * Tt(params) * Tt(output_height) * Tt(output_width)\n",
    "        list_pooling.append(flops)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    def register_hook(net):\n",
    "        childrens = list(net.children())\n",
    "        if not childrens:\n",
    "            if isinstance(net, torch.nn.Conv2d):\n",
    "                net.register_forward_hook(conv_hook)\n",
    "            if isinstance(net, torch.nn.Linear):\n",
    "                net.register_forward_hook(linear_hook)\n",
    "            if isinstance(net, torch.nn.BatchNorm2d):\n",
    "                net.register_forward_hook(bn_hook)\n",
    "            if isinstance(net, torch.nn.ReLU):\n",
    "                net.register_forward_hook(relu_hook)\n",
    "            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n",
    "                net.register_forward_hook(pooling_hook)\n",
    "            return\n",
    "        for c in childrens:\n",
    "                register_hook(c)\n",
    "\n",
    "    resnet =my_models\n",
    "     #EDSR(args)\n",
    "    register_hook(resnet)\n",
    "    with torch.no_grad():\n",
    "        input = torch.rand(1,1,224,224)\n",
    "        out = resnet(input)\n",
    "    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling))\n",
    "    print('Number of FLOPs: %.2fG' % (total_flops / 1e9)+'\\n')\n",
    "mo=ESPCN()#EDSR(args)\n",
    "print_model_parm_flops(mo)\n",
    "print_model_parm_nums(mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
